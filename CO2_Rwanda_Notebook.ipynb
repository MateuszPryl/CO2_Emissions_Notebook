{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./playground-series-s3e20/train.csv\")\n",
    "test_df = pd.read_csv(\"./playground-series-s3e20/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data contains information about 7 main features: SO2, CO, NO2, HCHO, UV_Aerosol_Index, O3, Cloud and additional features tied to the main ones.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Missing data identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = train_df.isna().sum()\n",
    "\n",
    "fig = px.bar(values, text_auto='.2s',\n",
    "        title=\"Number of missing values in columns\", width=1300, height=800)\n",
    "\n",
    "fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is missing from almost all columns. In some cases there are only small portions of data missing whereas f.x. in columns containing UV data over 90% of data is missing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Emission data time series in particular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_week_year(row):\n",
    "    # Calculate the first day of the given year\n",
    "    # print(row)\n",
    "    first_day = datetime(int(row.year), 1, 1)\n",
    "\n",
    "    # Calculate the number of days to the first day of the first week\n",
    "    days_to_first_weekday = (1 - first_day.weekday()) % 7\n",
    "\n",
    "    # Calculate the date of the first day of the given week\n",
    "    start_date = first_day + timedelta(days=days_to_first_weekday + 7 * (int(row.week_no) - 1))\n",
    "\n",
    "    return start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[['year', 'week_no', 'emission', 'latitude', 'longitude']]\n",
    "df['date'] = df.apply(date_from_week_year, axis=1)\n",
    "df.drop(['year', 'week_no'], axis=1, inplace=True)\n",
    "chart_df = df[(df['latitude'] == -0.510) & (df['longitude'] == 29.290)]\n",
    "chart_df\n",
    "\n",
    "fig = px.line(chart_df, x='date', y='emission', title='Emission data over the time period from: (-0.51, 29.29) location')\n",
    "fig.update_layout(\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_by_year = train_df.groupby('year')['emission'].count()\n",
    "\n",
    "fig = px.bar(train_df, x=train_df['year'].unique() , y=data_count_by_year, title=\"Emission data per year distribution\")\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count_by_week = train_df.groupby('week_no')['emission'].count()\n",
    "\n",
    "fig = px.bar(train_df, x=train_df['week_no'].unique() , y=data_count_by_week, title=\"Emission data per year distribution\")\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "    )\n",
    "    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 25 correlated features \n",
    "top25 = abs(train_df.corr()['emission']).sort_values(ascending = False).head(20)\n",
    "top25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df[list(top25.index)].corr()\n",
    "plt.figure(figsize = (13, 8))\n",
    "sns.heatmap(corr, cmap=plt.cm.CMRmap_r , annot = True, center = 0)\n",
    "plt.title('Correlation matrix', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import numeric\n",
    "\n",
    "\n",
    "def correlation_threshold(dataset, threshold=0.85):\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr(numeric_only=True)\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = correlation_threshold(train_df, 0.9)\n",
    "print(correlated_features)\n",
    "print(f'There are {len(correlated_features)} correlated features with correclation coefficient over 0.9')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 dependent features which are highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['ID_LAT_LON_YEAR_WEEK', 'emission'], axis=1).fillna(0)\n",
    "y = train_df['emission']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "model = CatBoostRegressor(silent=True, random_state=41)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model_rf = RandomForestRegressor(random_state=41)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_rf = model_rf.predict(X_val)\n",
    "\n",
    "# Measuring the accuracy of the model\n",
    "print(f'RMSE Score: {mean_squared_error(y_val, y_pred, squared=False)}')\n",
    "print(f'RMSE Score RF: {mean_squared_error(y_val, y_pred_rf, squared=False)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on the test set\n",
    "df = test_df.drop(['ID_LAT_LON_YEAR_WEEK'], axis = 1).fillna(0)\n",
    "# predictions = model.predict(df)\n",
    "predictions = model_rf.predict(df)\n",
    "\n",
    "# # Create a submission file\n",
    "sub_file = pd.DataFrame({'ID_LAT_LON_YEAR_WEEK': test_df.ID_LAT_LON_YEAR_WEEK, 'emission': predictions})\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
